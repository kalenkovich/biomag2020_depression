{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from bids import BIDSLayout\n",
    "import numpy as np\n",
    "import mne\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.cluster.center_initializer import random_center_initializer\n",
    "from pyclustering.utils.metric import distance_metric, type_metric\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import euclidean\n",
    "import ot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_root = Path(os.environ['biomag2020_data-bids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01_preprocessing': BIDS Layout: ...s\\derivatives\\01_preprocessing | Subjects: 33 | Sessions: 66 | Runs: 0,\n",
       " '02_eigenvalues': BIDS Layout: ...ids\\derivatives\\02_eigenvalues | Subjects: 33 | Sessions: 66 | Runs: 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = BIDSLayout(bids_root, validate=True, derivatives=True)\n",
    "layout.derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds files that contain eigenvalues of the normalized Laplacian of the sensor-to-sensor correlation matrix for each session.\n",
    "The eigenvalues are calculated in the `create_eigenvalues` rule in `Snakefile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue_files = layout.get(suffix='eigenvalues', extension='npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to know which eigenvalues belong to which subject and session in order to run the clustering.\n",
    "This information is used later in an attempt to evaluate the results of the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [f.entities['subject'] for f in eigenvalue_files]\n",
    "sessions = [f.entities['session'] for f in eigenvalue_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigs_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BQBBKEBX</td>\n",
       "      <td>1457629800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BQBBKEBX</td>\n",
       "      <td>1458832200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BYADLMJH</td>\n",
       "      <td>1416503760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BYADLMJH</td>\n",
       "      <td>1417706220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CECMHHYP</td>\n",
       "      <td>1364481360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eigs_id   subject     session\n",
       "0        0  BQBBKEBX  1457629800\n",
       "1        1  BQBBKEBX  1458832200\n",
       "2        2  BYADLMJH  1416503760\n",
       "3        3  BYADLMJH  1417706220\n",
       "4        4  CECMHHYP  1364481360"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    pd.DataFrame(\n",
    "        columns=['subject', 'session'],\n",
    "        data=zip(subjects, sessions))\n",
    "    .reset_index()\n",
    "    .rename(columns=dict(index='eigs_id')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the eigenvalues into a single matrix.\n",
    "\n",
    "Since the eigenvalues are distributed in [0, 2] (property of the Laplacian), we clip them to avoid rounding problems (for example, 2,0001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs_all = np.stack([np.load(f) for f in eigenvalue_files])\n",
    "eigs_all = eigs_all.clip(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent the eigenspectra, we will count the number of values in certain bins.\n",
    "These bins have to be shared between all the spectra for this to work.\n",
    "Our solution is to take all the eigenvalues from all sessions together and use the quantiles as the bin limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100\n",
    "bins = np.quantile(eigs_all.flatten(), np.linspace(0, 1, n_bins + 1))\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix of distances between bins - we will need it for the function that calculate the Wasserstein barycenters.\n",
    "The `wasserstein_distance` presumably will use a similar calculation of the \"earth moving\" cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.asarray([[abs(bc2 - bc1) for bc1 in bin_centers] for bc2 in bin_centers])\n",
    "M /= M.max()  # we've seen a recommendation to do this for numerical reasons in a couple of places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert samples to pmfs/pdfs.\n",
    "\n",
    "Because the bins have different widths, pmf and pdf represenations of the distributions are different.\n",
    "For pmf, the number corresponding to the bin is an estimate of the probability of an eigenvalue falling in that bin.\n",
    "For pdf, that estimate is that number times the bin width.\n",
    "\n",
    "We haven't really reached a conclusion as to which way makes more sense.\n",
    "Some things to consider:\n",
    "- The eigenvalue spectra are very dense near `1` resulting in narrow bins and thus pdfs giving larger weight to these eigenvalues.\n",
    "- We don't know which represenation `pot.barycenter` and `wasserstein_distance` expect as input. Does it matter?\n",
    "- Should we normalize the output of `pot.barycenter` so that the total probability is still `1`? Intuitively, we should.\n",
    "- A way to check the previous two points is to see how the distance changes when one of the distributions is multiplied by a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_type = 'pmf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if histogram_type == 'pmf':\n",
    "    histograms = np.asarray([np.histogram(spectrum, bins=bins)[0] for spectrum in eigs_all])\n",
    "    data = (histograms.T / histograms.sum(axis=1)).T\n",
    "elif histogram_type == 'pdf':\n",
    "    data = np.asarray([np.histogram(spectrum, bins=bins, density=True)[0] for spectrum in eigs_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `kmeans` class from `pyclustering` allows us to use a custom distance function but not a custom cluster center calculation.\n",
    "Thus, we had to subclass it and override the corresponding method.\n",
    "We could just implement k-means from scratch but that would become increasingly more complicated to do once we switched to other clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(kmeans):\n",
    "    def _kmeans__update_centers(self):\n",
    "        \"\"\"!\n",
    "        @brief Calculate centers of clusters in line with contained objects.\n",
    "\n",
    "        @return (numpy.array) Updated centers.\n",
    "\n",
    "        \"\"\"\n",
    "        numpy = np\n",
    "        \n",
    "        dimension = self._kmeans__pointer_data.shape[1]\n",
    "        centers = numpy.zeros((len(self._kmeans__clusters), dimension))\n",
    "\n",
    "        for index in range(len(self._kmeans__clusters)):\n",
    "            cluster_points = self._kmeans__pointer_data[self._kmeans__clusters[index], :]\n",
    "            # centers[index] = cluster_points.mean(axis=0)\n",
    "            centers[index] = ot.barycenter(cluster_points.T, M=self.M, reg=self.reg)\n",
    "            \n",
    "        return numpy.array(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2  # the number of clusters for the algorithm to look for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wasserstein distance metric that `KMeans` will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasserstein_metric = distance_metric(type_metric.USER_DEFINED, \n",
    "                                     func=lambda x, y: wasserstein_distance(bin_centers, bin_centers, x, y))\n",
    "\n",
    "# TODO: This code is a bit fragile because we use `bin_centers` which is a public notebook-level variable.\n",
    "# Couldn't find another way because the metric function will only be given the two spectra to compare.\n",
    "# One other option would be to include the bin centers in the spectra themselves either simply adding them at the end\n",
    "# or putting them into a second row. Not quite sure what unintended consequences this might have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_centers = random_center_initializer(data, k, random_state=3).initialize()\n",
    "kmeans_instance = KMeans(data=data, initial_centers=initial_centers, metric=wasserstein_metric)\n",
    "\n",
    "# The distance/cost matrix\n",
    "kmeans_instance.M = M\n",
    "\n",
    "# The regularization parameter\n",
    "# We don't know how to set this parameter properly.\n",
    "# What we do know is that larger values -> the barycenter depends less on the data.\n",
    "# Too large -> the barycenters are essentially the same for any set of spectra.\n",
    "kmeans_instance.reg = 0.05  \n",
    "\n",
    "# TODO: A better option would have been to override __init__ but we couldn't figure out quickly how to do it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_instance.process()\n",
    "final_centers = kmeans_instance.get_centers()\n",
    "clusters = kmeans_instance.get_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>eigs_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id  eigs_id\n",
       "0           2        0\n",
       "1           2        1\n",
       "2           1        2\n",
       "3           2        3\n",
       "4           1        4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment = pd.DataFrame(columns=['cluster_id', 'eigs_id'],\n",
    "             data=[(cluster_id, eigs_id) \n",
    "                     for cluster_id, cluster in enumerate(clusters, 1)\n",
    "                     for eigs_id in cluster\n",
    "                    ]\n",
    "            ).sort_values(by='eigs_id').reset_index(drop=True)\n",
    "cluster_assignment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know which subjects are depressed/healthy and in which sessions they are under ketamine or sober.\n",
    "Therefore, we can't do straight calculation of misclustered subjects/session.\n",
    "What we have to resort to are the indirect measures:\n",
    "- Did both sessions get into the *same* depressed/healthy cluster.\n",
    "- Did two session get into *different* ketamine/sober clusters.\n",
    "- Do the sizes of depressed/healthy clusters correspond to the actual numbers of depressed/healthy participants (22/14 respectively). Complicated by the fact that we had to exclude three participant for technical reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters.\n",
    "\n",
    "Can be smaller than `k` if at some step no spectra were assigned to one of the clusters.\n",
    "Indicative of some problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of spectra per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 49]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(c) for c in clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cluster id for each subject/session.\n",
    "\n",
    "TODO: I hate dataframes named df even though I was the one who named them in this notebook. EK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigs_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BQBBKEBX</td>\n",
       "      <td>1457629800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BQBBKEBX</td>\n",
       "      <td>1458832200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BYADLMJH</td>\n",
       "      <td>1416503760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BYADLMJH</td>\n",
       "      <td>1417706220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CECMHHYP</td>\n",
       "      <td>1364481360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eigs_id   subject     session  cluster_id\n",
       "0        0  BQBBKEBX  1457629800           2\n",
       "1        1  BQBBKEBX  1458832200           2\n",
       "2        2  BYADLMJH  1416503760           1\n",
       "3        3  BYADLMJH  1417706220           2\n",
       "4        4  CECMHHYP  1364481360           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.merge(cluster_assignment, on='eigs_id')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of subjects with distinct combinations of session clustering.\n",
    "\n",
    "Each `c_1, c_2, n` row tells us how many subjects had one session assigned to cluster `c_1` and one to cluster `c_2`.\n",
    "If `c_1 == c_2`, both sessions were assigned to the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cluster_id, min)  (cluster_id, max)\n",
       "1                  1                     2\n",
       "                   2                    13\n",
       "2                  2                    18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('subject').agg(dict(cluster_id=['min', 'max'])).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of subject with sessions clustered into two clusters vs. one cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20\n",
       "2    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('subject').agg(dict(cluster_id=['min', 'max'])).nunique(axis=1).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
